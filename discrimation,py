# -*- coding:utf8
from gensim import models
import time
start_time = time.time()
print ('Step1:Read your dictionary results..')

model = models.word2vec.Word2Vec.load('/Volumes/SPACE/word2vecAndGieba/test1116_summary/vector_for_word_training/3_wikiTrain/dictionary_dim_100_fast',mmap='r')

# def txtToArray(filename):
# 	f = open(filename, 'r+')
# 	array=[]
# 	for line in f:
# 		array.append(line.replace('\n',''))
# 	return array

# print(txtToArray('word_v1.txt'))

wordOrigin = ['娘娘腔','男人婆','母豬','CCR','拜金女','公主病','gay','玻璃','不男不女','ㄈㄈ尺','狗','娘炮','女生','男生']
wordAfter = []
for k in wordOrigin:
	try:
		wordAfter.append(model.most_similar(k,topn=30))
	except:
		print('exception:'+k)
# print(wordAfter)
f = open('word_nogood.txt', 'w')
for i in wordOrigin:
	f.write(i+'\n')
for i in wordAfter:
	for i2 in i:
		word = i2[0]
		# print (word)
		f.write(word+'\n')
f.close()
wordOriginString=""
# count = 0

# for i in wordOrigin:
# 	count = count+1
# 	if count == 1:
# 		wordOriginString = wordOriginString+i
# 	else:
# 		wordOriginString = wordOriginString+" "+i
# # print(wordOriginString)
# print(model.most_similar(positive=wordOriginString.split(" "), negative=[u"醫院"],topn=5))

# print(model.most_similar(positive=u"巴黎 柏林".split(" "), negative=[u"法國"],topn=5))

over_time = time.time()

print(over_time-start_time)